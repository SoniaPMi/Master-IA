{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RepasoKeras_APIFuncional.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoniaPMi/Master-IA/blob/main/RepasoKeras_APIFuncional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ1tIWQ3soHE"
      },
      "source": [
        "# Keras\n",
        "\n",
        "Keras es una librería construída para el prototipado rápido de modelos de deep learning. Las ventajas de Keras frente a otros frameworks de deep learning son obvios:\n",
        "\n",
        "- Rápido prototipado (entrenamiento y evaluación) de modelos de deep learning.\n",
        "\n",
        "- Posee una api sencilla con la que se pueden añadir estructuras complejas en redes de neuronas (capas).\n",
        "\n",
        "- Se integra con las herramientas de tensorflow de forma nativa.\n",
        "\n",
        "Keras permite construir modelos utilizando diferentes tipos de api (Application Porgram Interface). Las distintas apis tienen sus ventajas e inconvenientes, en esta clase vamos a estudiar la api secuencial y la api funcional de Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE6_0KlCzQBg"
      },
      "source": [
        "# Keras Sequential API\n",
        "\n",
        "La api secuencial de Keras permite construir modelos añadiendo capas en forma de secuencia. Su uso es muy directo siguiendo los siguientes pasos:\n",
        "\n",
        "- Definimos el modelo utilizando la clase Sequential.\n",
        "\n",
        "- Añadimos capas al modelo utilizando el método .add()\n",
        "\n",
        "- Comppilamos el modelo utilizando el método .compile()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqkkRezH2Y-Y"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrkI4arDzPVX"
      },
      "source": [
        "# Ejemplo\n",
        "dataset = sns.load_dataset(\"iris\")\n",
        "#definimos modelo\n",
        "model = keras.models.Sequential()\n",
        "#definimos capas\n",
        "layer_1 = keras.layers.Dense(10, activation=\"relu\") #10 o otro num.\n",
        "output = keras.layers.Dense(3, activation=\"softmax\") #3 clases\n",
        "#añadimos modelo\n",
        "model.add(layer_1)\n",
        "model.add(output)\n",
        "#compilamos modelo\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sPqmTkl3Ld8"
      },
      "source": [
        "X = dataset.iloc[:,:-1]\n",
        "Y = dataset.iloc[:,-1:]\n",
        "Y_dummies = pd.get_dummies(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y_dummies)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBH3c6I65X8_",
        "outputId": "26eb3fbb-84e1-4a22-8716-3b1dfa0b349b"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=300)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 2.7838\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6395\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4954\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3568\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.2237\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.1024\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.9793\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.8741\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.7697\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6779\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.5874\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.5128\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4326\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3694\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3088\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2473\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1927\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1425\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0941\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0476\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0022\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9666\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9262\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8931\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8619\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8353\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8101\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7913\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7725\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7581\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7457\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7352\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7263\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7188\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7137\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7076\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7016\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.6971\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6931\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6887\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6853\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6807\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6769\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6731\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6694\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6659\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6623\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6587\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6552\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6517\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6484\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6453\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6420\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6385\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6353\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6323\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6291\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6261\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6239\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6201\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6171\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6141\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6118\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6083\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6059\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6029\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6002\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5977\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5948\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5923\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5899\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5871\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5847\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5823\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5798\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5772\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5747\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5723\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5699\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5676\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5652\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5629\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5606\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5585\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5564\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5539\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5518\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5496\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5475\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5453\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5434\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5410\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5390\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5369\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5349\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5326\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5307\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5290\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5271\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5252\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5232\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5212\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5192\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5172\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5154\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5134\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5118\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5100\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5079\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5060\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5046\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5028\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5006\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4988\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4971\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4954\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4940\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4928\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4910\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4889\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4871\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4851\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4837\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4817\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4804\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4784\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4768\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4752\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4736\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4719\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4708\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4686\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4670\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4654\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4639\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4624\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4608\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4592\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4579\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4563\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4546\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4532\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4519\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4503\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4487\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4473\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4461\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4444\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4431\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4418\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4405\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4389\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4374\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4361\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4348\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4338\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4322\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4306\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4293\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4279\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4267\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4254\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4240\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4226\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4213\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4200\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4189\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4175\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4160\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4147\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4133\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4122\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4108\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4097\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4084\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4069\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4057\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4044\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4030\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4019\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4007\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3994\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3982\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3969\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3958\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3944\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3933\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3919\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3907\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3896\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3882\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3872\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3859\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3848\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3836\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3822\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3807\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3798\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3784\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3771\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3761\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3748\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3736\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3727\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3711\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3699\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3688\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3679\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3668\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3656\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3647\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3635\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3621\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3607\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3603\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3585\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3573\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3561\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3552\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3538\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3527\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3516\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3508\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3492\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3484\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3471\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3460\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3447\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3436\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3426\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3414\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3404\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3391\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3382\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3369\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3358\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3347\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3336\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3325\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3314\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3308\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3297\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3282\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3271\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3264\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3250\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3238\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3232\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3217\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3207\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3208\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3187\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3178\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3165\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3155\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3141\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3132\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3124\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3111\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3102\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3095\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3079\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3068\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3060\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3053\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3042\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3033\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3022\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3012\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3000\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2989\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2981\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2968\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2959\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2951\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2940\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2930\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2920\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2909\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2900\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2890\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2881\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2871\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2866\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2855\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2846\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2832\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2822\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2816\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2804\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2794\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2786\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2777\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2766\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2759\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2747\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2747\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2729\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2720\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63fa237d50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65HyLVmZ53Mg",
        "outputId": "a73a52af-1a70-4ff3-f033-50d9e7e94557"
      },
      "source": [
        "# Realizar predicción\n",
        "model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.0353526e-03, 4.9319449e-01, 5.0377017e-01],\n",
              "       [9.6630925e-01, 3.3360798e-02, 3.2996800e-04],\n",
              "       [3.6704235e-03, 2.2835828e-01, 7.6797128e-01],\n",
              "       [1.5099961e-03, 2.0131424e-01, 7.9717577e-01],\n",
              "       [5.1280959e-03, 2.9775012e-01, 6.9712180e-01],\n",
              "       [9.5498073e-01, 4.4282209e-02, 7.3697499e-04],\n",
              "       [2.0415897e-02, 7.2674638e-01, 2.5283781e-01],\n",
              "       [1.4800873e-03, 1.5061863e-01, 8.4790128e-01],\n",
              "       [8.5952617e-03, 4.6006933e-01, 5.3133535e-01],\n",
              "       [1.8264536e-03, 1.3002703e-01, 8.6814648e-01],\n",
              "       [1.4237370e-03, 2.1912579e-01, 7.7945048e-01],\n",
              "       [8.2910974e-03, 2.8690818e-01, 7.0480072e-01],\n",
              "       [1.7189730e-02, 7.5024861e-01, 2.3256169e-01],\n",
              "       [9.7329390e-01, 2.6452707e-02, 2.5335886e-04],\n",
              "       [9.5079386e-01, 4.8638716e-02, 5.6740985e-04],\n",
              "       [3.4945726e-02, 8.1886816e-01, 1.4618613e-01],\n",
              "       [9.1810209e-01, 8.1010155e-02, 8.8770880e-04],\n",
              "       [4.3601156e-03, 3.2123908e-01, 6.7440081e-01],\n",
              "       [3.3622086e-03, 2.8294960e-01, 7.1368819e-01],\n",
              "       [4.3876696e-02, 7.0044559e-01, 2.5567773e-01],\n",
              "       [9.9246866e-01, 7.4869073e-03, 4.4456858e-05],\n",
              "       [9.9206746e-01, 7.8968033e-03, 3.5670615e-05],\n",
              "       [1.7457116e-02, 6.7856622e-01, 3.0397666e-01],\n",
              "       [9.7131753e-01, 2.8430637e-02, 2.5182983e-04],\n",
              "       [3.3264169e-03, 3.9487934e-01, 6.0179430e-01],\n",
              "       [2.0499909e-02, 6.4950573e-01, 3.2999438e-01],\n",
              "       [9.5022207e-01, 4.9066164e-02, 7.1174483e-04],\n",
              "       [9.7792838e-03, 4.6458018e-01, 5.2564055e-01],\n",
              "       [2.2075433e-02, 7.8077352e-01, 1.9715106e-01],\n",
              "       [9.8236555e-01, 1.7492872e-02, 1.4153404e-04],\n",
              "       [1.5441849e-03, 2.4366018e-01, 7.5479561e-01],\n",
              "       [9.8827457e-01, 1.1676574e-02, 4.8913804e-05],\n",
              "       [1.5283336e-03, 1.7608197e-01, 8.2238966e-01],\n",
              "       [2.6778837e-03, 1.6662310e-01, 8.3069903e-01],\n",
              "       [3.4250987e-03, 2.3517428e-01, 7.6140064e-01],\n",
              "       [1.1972948e-02, 5.2710724e-01, 4.6091977e-01],\n",
              "       [9.8008019e-01, 1.9688077e-02, 2.3180504e-04],\n",
              "       [6.3124960e-03, 4.1427600e-01, 5.7941145e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iDZAFdO7oWQ"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Entrenad un modelo de 3 capas densas utilizando la api secuencial de Keras para el dataset penguins. El objetivo es clasificar el sexo del pingüino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "TwN1QZOgRFzU",
        "outputId": "b6dc9ea2-f47d-4fd7-f3cc-779032e38a8c"
      },
      "source": [
        "dt2 = sns.load_dataset(\"penguins\")\n",
        "dt2.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0148c7b2-640c-4b90-b642-5fd6ade24041\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>190.0</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>38.9</td>\n",
              "      <td>17.8</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3625.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.2</td>\n",
              "      <td>19.6</td>\n",
              "      <td>195.0</td>\n",
              "      <td>4675.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>34.1</td>\n",
              "      <td>18.1</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3475.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>42.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>190.0</td>\n",
              "      <td>4250.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0148c7b2-640c-4b90-b642-5fd6ade24041')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0148c7b2-640c-4b90-b642-5fd6ade24041 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0148c7b2-640c-4b90-b642-5fd6ade24041');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  species     island  bill_length_mm  ...  flipper_length_mm  body_mass_g     sex\n",
              "0  Adelie  Torgersen            39.1  ...              181.0       3750.0    Male\n",
              "1  Adelie  Torgersen            39.5  ...              186.0       3800.0  Female\n",
              "2  Adelie  Torgersen            40.3  ...              195.0       3250.0  Female\n",
              "3  Adelie  Torgersen             NaN  ...                NaN          NaN     NaN\n",
              "4  Adelie  Torgersen            36.7  ...              193.0       3450.0  Female\n",
              "5  Adelie  Torgersen            39.3  ...              190.0       3650.0    Male\n",
              "6  Adelie  Torgersen            38.9  ...              181.0       3625.0  Female\n",
              "7  Adelie  Torgersen            39.2  ...              195.0       4675.0    Male\n",
              "8  Adelie  Torgersen            34.1  ...              193.0       3475.0     NaN\n",
              "9  Adelie  Torgersen            42.0  ...              190.0       4250.0     NaN\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNSvJgXHRV6s"
      },
      "source": [
        "#definimos modelo\n",
        "model2 = keras.models.Sequential()\n",
        "#definimos capas\n",
        "layer_1 = keras.layers.Dense(10, activation=\"relu\") #10 o otro num.\n",
        "layer_2 = keras.layers.Dense(5, activation=\"relu\") #10 o otro num.\n",
        "layer_3 = keras.layers.Dense(7, activation=\"relu\") #10 o otro num.\n",
        "output = keras.layers.Dense(2, activation=\"softmax\") #2 clases perq  tengo separado male female\n",
        "#añadimos modelo\n",
        "model2.add(layer_1)\n",
        "model2.add(layer_2)\n",
        "model2.add(layer_3)\n",
        "model2.add(output)\n",
        "#compilamos modelo\n",
        "model2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
        "#como estamos entre 0 y 1, la loss podria ser va binaria y usaria una sigmoid en la salida"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d49C0p5tR1RL"
      },
      "source": [
        "dt2.dropna(inplace=True)\n",
        "\n",
        "X = pd.get_dummies(dt2.iloc[:,:-1])\n",
        "Y = pd.get_dummies(dt2.iloc[:,-1:])\n",
        "#aqui pongo Y con dos clases, como tengo 2 dimensiones a la salida debo utilizar la funcion softmax\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
        "#"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW3ciFMASdW_",
        "outputId": "433bb8f4-9c75-4bef-f843-9f394fbf0afd"
      },
      "source": [
        "model2.fit(X_train, Y_train, epochs=300)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 14.5759\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5655\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2751\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0610\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3663\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0320\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0154\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9091\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8839\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8667\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8218\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8756\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3798\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9985\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7382\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6892\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6910\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8435\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7756\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8479\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7718\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9721\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7738\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6127\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7410\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6956\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7359\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7701\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7015\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7510\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6535\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6172\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6586\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6046\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5990\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6028\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5733\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5125\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6256\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5700\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7207\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8480\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7771\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6565\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5205\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4897\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6552\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6822\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6507\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7015\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4866\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5047\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5373\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5959\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7622\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7271\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5503\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5583\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5284\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5191\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5104\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5350\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5797\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5520\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4793\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5579\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5487\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5395\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4999\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4825\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5028\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5804\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5685\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5671\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5920\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7535\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6688\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7420\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1773\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8510\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7806\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5746\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4998\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8009\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9578\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5062\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5641\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5289\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4734\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5987\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7450\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5944\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6259\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7444\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7535\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5628\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6151\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4913\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5674\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5493\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4925\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5208\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5573\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4748\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6233\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6468\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6643\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5128\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6072\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4971\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4762\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5386\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4636\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4503\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5378\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5430\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7145\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5410\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4678\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4612\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4576\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4446\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4822\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4698\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5606\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6960\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5904\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5411\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5555\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5861\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5385\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5914\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8888\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9522\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9034\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6145\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5233\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4792\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4877\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6076\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4750\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4406\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5251\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5247\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6204\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5396\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6371\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4622\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4627\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4891\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4412\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5805\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8174\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6611\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6856\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9141\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1881\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5789\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6054\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4648\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4553\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5255\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5683\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9660\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9702\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5698\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6117\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5912\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4814\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5369\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4556\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4793\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7014\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5078\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5489\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5871\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5082\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5713\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7699\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5688\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5005\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5721\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5300\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6682\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5529\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4675\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4679\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4340\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5984\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5804\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5483\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4549\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4507\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5569\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5678\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5538\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4977\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5330\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7183\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8139\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6367\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5276\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4201\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5711\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5827\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4646\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6488\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5200\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5024\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4410\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4849\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5629\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5970\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5394\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5073\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5236\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4647\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9493\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7772\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6716\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6193\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5330\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6646\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5015\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5742\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6385\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8662\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6453\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5718\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8306\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8129\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6060\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4465\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5384\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5107\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5623\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5964\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5216\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4177\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4237\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4545\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5066\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4976\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4253\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4634\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6063\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7427\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8000\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6375\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7431\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7077\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7097\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7490\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6617\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9720\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0378\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7708\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5410\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5309\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7514\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4889\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4970\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6717\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6780\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7573\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7900\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8012\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5427\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4302\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4292\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4276\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4060\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4420\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4580\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4410\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4312\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5889\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5401\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4919\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5454\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8223\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8094\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6588\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6175\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7484\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5012\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5265\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5672\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5100\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5124\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5653\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6119\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4701\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4601\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4979\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4564\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4674\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4946\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7143\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9840\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63f9edefd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BwC015CTMP0",
        "outputId": "0308a13e-3c10-42f7-85d7-f8ade88a2ae0"
      },
      "source": [
        "# Realizar predicción\n",
        "model2.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48829862, 0.51170135],\n",
              "       [0.50395197, 0.49604806],\n",
              "       [0.5660823 , 0.43391776],\n",
              "       [0.44926423, 0.5507357 ],\n",
              "       [0.5130433 , 0.48695666],\n",
              "       [0.5216806 , 0.47831944],\n",
              "       [0.43006882, 0.5699312 ],\n",
              "       [0.4498684 , 0.5501316 ],\n",
              "       [0.47555205, 0.524448  ],\n",
              "       [0.4525775 , 0.54742247],\n",
              "       [0.45171192, 0.54828805],\n",
              "       [0.52268565, 0.4773143 ],\n",
              "       [0.41321445, 0.58678555],\n",
              "       [0.52571887, 0.47428116],\n",
              "       [0.5257531 , 0.4742469 ],\n",
              "       [0.5153036 , 0.48469642],\n",
              "       [0.5803056 , 0.4196944 ],\n",
              "       [0.54278   , 0.45722005],\n",
              "       [0.4891489 , 0.51085114],\n",
              "       [0.5256846 , 0.47431538],\n",
              "       [0.5096271 , 0.4903729 ],\n",
              "       [0.4409958 , 0.5590042 ],\n",
              "       [0.4783423 , 0.52165776],\n",
              "       [0.458004  , 0.541996  ],\n",
              "       [0.38836062, 0.6116393 ],\n",
              "       [0.50055695, 0.49944305],\n",
              "       [0.5057905 , 0.49420956],\n",
              "       [0.5480688 , 0.45193112],\n",
              "       [0.49860767, 0.50139236],\n",
              "       [0.4033759 , 0.59662414],\n",
              "       [0.47272915, 0.5272709 ],\n",
              "       [0.53164256, 0.4683575 ],\n",
              "       [0.56883687, 0.4311631 ],\n",
              "       [0.3942374 , 0.6057626 ],\n",
              "       [0.41566584, 0.5843342 ],\n",
              "       [0.47850218, 0.52149785],\n",
              "       [0.5257797 , 0.47422025],\n",
              "       [0.5205154 , 0.47948465],\n",
              "       [0.52873874, 0.47126126],\n",
              "       [0.54878306, 0.45121694],\n",
              "       [0.40674782, 0.5932522 ],\n",
              "       [0.43261763, 0.5673824 ],\n",
              "       [0.50162506, 0.49837497],\n",
              "       [0.4462496 , 0.5537504 ],\n",
              "       [0.44163537, 0.5583646 ],\n",
              "       [0.5453538 , 0.45464617],\n",
              "       [0.42397964, 0.57602036],\n",
              "       [0.43328446, 0.5667156 ],\n",
              "       [0.5133826 , 0.48661745],\n",
              "       [0.5395595 , 0.46044055],\n",
              "       [0.42414364, 0.5758564 ],\n",
              "       [0.52266663, 0.47733337],\n",
              "       [0.4614718 , 0.5385282 ],\n",
              "       [0.45169306, 0.54830694],\n",
              "       [0.5346277 , 0.4653723 ],\n",
              "       [0.5083992 , 0.49160084],\n",
              "       [0.5501354 , 0.44986463],\n",
              "       [0.45778048, 0.54221946],\n",
              "       [0.55631673, 0.4436833 ],\n",
              "       [0.45726168, 0.5427383 ],\n",
              "       [0.5120712 , 0.48792887],\n",
              "       [0.46732035, 0.5326796 ],\n",
              "       [0.4964905 , 0.50350946],\n",
              "       [0.5036163 , 0.49638373],\n",
              "       [0.4711434 , 0.5288566 ],\n",
              "       [0.5430299 , 0.45697013],\n",
              "       [0.48073006, 0.51926994],\n",
              "       [0.5305671 , 0.46943283],\n",
              "       [0.5002594 , 0.4997406 ],\n",
              "       [0.50524503, 0.494755  ],\n",
              "       [0.52004313, 0.4799569 ],\n",
              "       [0.5466739 , 0.45332617],\n",
              "       [0.5488927 , 0.45110738],\n",
              "       [0.5091428 , 0.49085718],\n",
              "       [0.51409155, 0.48590842],\n",
              "       [0.42212123, 0.57787883],\n",
              "       [0.3862388 , 0.6137612 ],\n",
              "       [0.39454356, 0.6054565 ],\n",
              "       [0.5139696 , 0.4860304 ],\n",
              "       [0.5093411 , 0.4906589 ],\n",
              "       [0.5316083 , 0.46839163],\n",
              "       [0.5417157 , 0.4582843 ],\n",
              "       [0.52880716, 0.47119284],\n",
              "       [0.56899965, 0.4310003 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLCbHARt7xdw"
      },
      "source": [
        "# Eliminar capas de un modelo secuencial.\n",
        "\n",
        "Es posible eliminar capas de un modelo secuencial utilizando el método .pop()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAWJg4OYP73Q",
        "outputId": "81750a00-8778-483b-b78c-d4dbd7d3bbcf"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.dense.Dense at 0x7f4ad35ba650>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6jgDxFbP-4e",
        "outputId": "15b6d2dc-5122-4743-e29d-802c413a00a1"
      },
      "source": [
        "model.layers[0].weights #son los W de las diferentes capas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense/kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
              " array([[ 0.5478236 , -0.4252265 , -0.41459036, -0.17898205,  0.18284541,\n",
              "          0.36025372,  0.13179503, -0.3643138 ,  0.36933488,  0.00672349],\n",
              "        [-0.10433403,  0.2546515 , -0.64266753, -0.64485687,  0.5540829 ,\n",
              "          0.82146364,  0.34323695,  0.0020631 ,  0.44959253,  0.27308536],\n",
              "        [ 0.80731815, -0.00590283,  0.10032845, -0.23086575, -0.7480583 ,\n",
              "         -0.52452904, -0.13693978, -0.27311718,  0.18949164, -0.72750664],\n",
              "        [ 0.38672787, -0.6218965 , -0.3837358 , -0.5141902 ,  0.09003341,\n",
              "         -0.9982998 ,  0.22708744, -0.47148582, -0.9395914 , -0.69880164]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=\n",
              " array([-0.21253285,  0.        ,  0.        ,  0.        ,  0.23966628,\n",
              "         0.44172528, -0.14751875,  0.        ,  0.28619382, -0.11556315],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNrvfx1qQFWM",
        "outputId": "2fea2dfa-6931-4452-9454-c870b8e78bce"
      },
      "source": [
        "model.layers[0].weights[0] #son los w de la primera capa (10 columnas = 10 neuronas) y 4 filas, salidas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'dense/kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
              "array([[ 0.5478236 , -0.4252265 , -0.41459036, -0.17898205,  0.18284541,\n",
              "         0.36025372,  0.13179503, -0.3643138 ,  0.36933488,  0.00672349],\n",
              "       [-0.10433403,  0.2546515 , -0.64266753, -0.64485687,  0.5540829 ,\n",
              "         0.82146364,  0.34323695,  0.0020631 ,  0.44959253,  0.27308536],\n",
              "       [ 0.80731815, -0.00590283,  0.10032845, -0.23086575, -0.7480583 ,\n",
              "        -0.52452904, -0.13693978, -0.27311718,  0.18949164, -0.72750664],\n",
              "       [ 0.38672787, -0.6218965 , -0.3837358 , -0.5141902 ,  0.09003341,\n",
              "        -0.9982998 ,  0.22708744, -0.47148582, -0.9395914 , -0.69880164]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4a4s7_V6dRW"
      },
      "source": [
        "model2.pop() #borra la última capa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlfnCZkVV0yC",
        "outputId": "d3d79c32-7b6e-47a8-d313-d9c38d546758"
      },
      "source": [
        "model2.layers #quito la ultima capa, en model 2 me queda con las 3 layers \n",
        "#si cada capa se dedica a algo, y me dejo la capa del controrno por ejemplo, y me quedaria en la salida el controrno"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.dense.Dense at 0x7f4a505fae50>,\n",
              " <keras.layers.core.dense.Dense at 0x7f4a5079e910>,\n",
              " <keras.layers.core.dense.Dense at 0x7f4a50613810>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLykN8GY8SZI",
        "outputId": "dec3c584-6756-4849-927a-355ba6cfef67"
      },
      "source": [
        "model.predict(X_train).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(249, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsapglaJQ2k_",
        "outputId": "990c7552-8552-47ee-ba9b-4adc50bb3ca3"
      },
      "source": [
        "model.predict(X_train) #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 48.1,  15.1, 209. , ...,   1. ,   0. ,   0. ],\n",
              "       [ 34.6,  17.2, 189. , ...,   0. ,   0. ,   1. ],\n",
              "       [ 48.4,  16.3, 220. , ...,   1. ,   0. ,   0. ],\n",
              "       ...,\n",
              "       [ 41.1,  17.6, 182. , ...,   0. ,   0. ,   1. ],\n",
              "       [ 48.7,  15.1, 222. , ...,   1. ,   0. ,   0. ],\n",
              "       [ 37. ,  16.5, 185. , ...,   0. ,   1. ,   0. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcllTz2Q8UH_",
        "outputId": "91de0926-dad2-42c6-df88-45322243744e"
      },
      "source": [
        "len(model.layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HgsPWzi9OMr"
      },
      "source": [
        "# API Funcional\n",
        "\n",
        "La api funcional de Keras plantea construir un modelo mediante funciones. Las capas definidas en esta api se estructuran como funciones de Python cuya entrada es la salida de la capa anterior. Para construir un modelo utilizando la API Funcional de Keras hay que seguir los siguientes pasos:\n",
        "\n",
        "- Definir la entrada con keras.layers.Input()\n",
        "- Definir las capas de keras.layers\n",
        "- Definir el modelo con keras.models.Model()\n",
        "- Compilar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZgVO8rk_5Rg"
      },
      "source": [
        "dataset = sns.load_dataset(\"iris\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myGihdhu9NhT"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(4,))\n",
        "\n",
        "layer_1 = keras.layers.Dense(5, activation=\"relu\")(input_layer)\n",
        "\n",
        "output = keras.layers.Dense(3, activation=\"softmax\")(layer_1)\n",
        "\n",
        "#output = output_def(layer_1)\n",
        "\n",
        "model = keras.Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyqA_4wR8ZD3"
      },
      "source": [
        "X = dataset.iloc[:,:-1]\n",
        "Y = dataset.iloc[:,-1:]\n",
        "Y_dummies = pd.get_dummies(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y_dummies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUi4MMH2_9hI",
        "outputId": "d7f8c383-0003-433c-b5b5-bf1488f233d9"
      },
      "source": [
        "model.fit(X_train,Y_train, epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2232\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.1738\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.1270\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.0780\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.0322\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.9847\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.9412\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.8948\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.8511\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.8083\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.7663\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.7259\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6869\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6497\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6097\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.5755\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5403\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5050\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4727\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4403\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4076\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3772\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3470\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3191\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2901\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2642\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2384\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2134\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1902\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1671\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1453\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1224\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1010\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0813\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0617\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0435\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0247\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0087\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9896\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9741\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9596\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9438\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9296\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9162\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9028\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8907\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8781\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8672\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8550\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8439\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8336\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8233\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8130\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8033\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7940\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7847\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7751\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7661\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7570\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7483\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7394\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7318\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7227\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7152\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7076\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6999\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6922\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6857\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6782\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6716\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6652\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6582\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6522\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6461\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6398\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6340\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6285\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6228\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6174\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6116\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6063\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6013\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5958\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5911\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5861\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5817\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5771\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5724\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5679\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5635\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5593\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5551\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5509\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5469\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5427\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5389\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5350\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5310\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5273\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5234\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5198\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5161\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5125\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5091\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5058\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5022\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4989\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4957\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4923\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4892\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4859\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4828\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4799\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4767\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4739\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4710\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4681\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4652\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4625\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4598\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4571\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4543\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4516\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4490\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4464\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4438\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4414\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4387\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4362\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4336\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4312\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4291\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4266\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4241\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4217\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4197\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4170\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4147\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4124\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4101\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4079\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4058\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4034\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4012\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3990\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3968\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3947\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3925\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3903\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3882\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3861\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3841\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3821\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3802\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3780\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3759\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3739\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3720\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3699\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3679\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3662\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3641\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3622\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3602\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3584\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3566\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3548\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3529\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3509\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3491\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3471\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3453\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3436\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3418\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3400\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3381\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3364\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3347\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3330\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3312\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3294\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3276\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3260\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3243\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3227\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3211\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3195\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3177\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3162\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3146\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3129\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3115\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3099\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3083\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3067\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3052\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3036\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3021\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3007\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a5439d0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8CFBzwKBEYH"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Construid un modelo de 3 capas densas utilizando la API Funcional de Keras sobre el dataset penguins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a12hrOu0BkH3"
      },
      "source": [
        "# Acceder a las capas intermedias de un modelo\n",
        "\n",
        "A veces es interesante poder acceder a la salida de una capa intermedia de un modelo entrenado previamente. Para ello es necesario construir un nuevo modelo definiendo una nueva salida.\n",
        "\n",
        "Una vez definida la nueva salida es posible aplicar análisis dimensional (comprobar las dimensiones de la salida) para comprender más acerca del modelo y si hemos elegido la capa correcta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMvVKvM4__S5"
      },
      "source": [
        "new_output = model.layers[1]\n",
        "model_2 = keras.Model(inputs=input_layer, outputs=new_output.output)\n",
        "model_2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "3Fz7CLDmZpHr",
        "outputId": "7d4d8f3f-aeaf-4054-fd5c-63e04240019a"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAAD/CAYAAAC0J5mLAAAABmJLR0QA/wD/AP+gvaeTAAAaGUlEQVR4nO3da1BU5x0G8Ocsl10WWVCLglkgglbijTSTKC5eaK1p1KmTyKokeMHUTtTerNGSqjXW1EktSejUSDNGY6b9gIuQ8ZaapNWGNB3IaOslUQEvI0hQQaWgLALCvx8s22yAV5CFs+DzmzkffPc95/3vOTyey+6eo4mIgIjaZNC7ACJvxoAQKTAgRAoMCJGC79cb8vPz8cYbb+hRC5GuVq5ciQkTJri1tdqDXLp0CTk5OT1WVF9WUFCAgoICvcugDsjJycGlS5datbfag7TYvXt3txb0IJgzZw4ArsveQNO0Ntt5DkKkwIAQKTAgRAoMCJECA0KkwIAQKTAgRAoMCJECA0KkwIAQKTAgRAoMCJECA0KkwIAQKXgkIH/5y18QHByM/fv3e2JxumtubkZGRgZsNluPjltQUIBHHnkEBoMBmqZh8ODB+M1vftOjNdxLbm4uoqOjoWkaNE1DWFgY5s+fr3dZ3abd34N0Rl+6c9DZs2exePFi/POf/0RcXFyPjh0fH48zZ87gqaeewocffoiioiKEhIT0aA33kpSUhKSkJAwbNgzXrl3DlStX9C6pW3lkDzJz5kxUV1fj+9//vicW1yV1dXX3/T//iRMn8NJLL2HZsmV49NFHPVxZ79SV9dkX9LlzkB07dqCiouK+5o2Li0Nubi5SUlJgNBo9XFnv1JX12Rd0OSCffvopIiMjoWka3nzzTQBAZmYmAgMDYTabsXfvXkyfPh0WiwVWqxVZWVmuef/whz/AZDJh0KBBWLp0KcLDw2EymWCz2fDZZ5+5+v30pz+Fv78/wsLCXG0/+tGPEBgYCE3TcO3aNQDAihUr8OKLL+L8+fPQNA3Dhg3r6tvzCr19ff7jH//AyJEjERwcDJPJhDFjxuDDDz8EACxZssR1PhMTE4Njx44BABYvXgyz2Yzg4GDs27cPANDU1IT169cjMjISAQEBGDt2LBwOBwDgd7/7HcxmM4KCglBRUYEXX3wRDz30EIqKiu6rZhf5GofDIW00K126dEkAyJYtW1xta9euFQBy6NAhqa6uloqKCpk0aZIEBgZKQ0ODq98LL7wggYGBcvr0abl9+7acOnVKnnjiCQkKCpLS0lJXv5SUFBk8eLDbuOnp6QJAKisrXW1JSUkSExPTqfrbMn78eImLi+vSMux2u9jt9k7P973vfU8ASFVVlavN29ZnTEyMBAcHd+j97N69WzZs2CA3btyQ69evS3x8vAwcONBtDB8fH/nyyy/d5nvuuedk3759rn+vWrVKjEaj5OTkSFVVlaxZs0YMBoMcOXLEbR397Gc/ky1btsjs2bPlzJkzHaoRgDgcjlbt3X6IZbPZYLFYEBoaiuTkZNTW1qK0tNStj6+vLx555BEYjUaMHDkSmZmZuHnzJnbu3Nnd5fU6vXF92u12vPzyy+jfvz8GDBiAWbNm4fr166isrAQALFu2DE1NTW711dTU4MiRI5gxYwYA4Pbt28jMzMQzzzyDpKQkhISEYN26dfDz82v1vn7729/ixz/+MXJzcxEbG9ul2nv0HMTf3x8A0NjYqOz3+OOPw2w2o7CwsCfK6rV66/r08/MDcPeQCQC+853v4Jvf/Cbeeecd1xXRXbt2ITk5GT4+PgCAoqIiOJ1OjB492rWcgIAAhIWFdev78tqTdKPR6PofhrpOz/X5/vvvIzExEaGhoTAajfjFL37h9rqmaVi6dCkuXLiAQ4cOAQD+9Kc/4Qc/+IGrT21tLQBg3bp1rnMWTdNQUlICp9PZbbV7ZUAaGxvxn//8B1arVe9S+oSeXp+ffPIJMjIyAAClpaV45plnEBYWhs8++wzV1dXYvHlzq3lSU1NhMpmwfft2FBUVwWKxICoqyvV6aGgoACAjIwMi4jbl5+d323vxyAeFnvbxxx9DRBAfH+9q8/X1veehBLWtp9fnv/71LwQGBgIAPv/8czQ2NmL58uWIjo4G0PZN2vr374958+Zh165dCAoKwg9/+EO31yMiImAymXD8+PFuqbk9XrEHaW5uRlVVFe7cuYOTJ09ixYoViIyMRGpqqqvPsGHDcOPGDezZsweNjY2orKxESUlJq2UNGDAA5eXluHjxIm7evPlAhkqv9dnY2IirV6/i448/dgUkMjISAPC3v/0Nt2/fxtmzZ90uOX/VsmXLUF9fjwMHDrT60NlkMmHx4sXIyspCZmYmampq0NTUhLKyMly+fLmzq6jjvn5Zq7OXebds2SJhYWECQMxms8yaNUu2bt0qZrNZAMjw4cPl/Pnzsm3bNrFYLAJAoqKipLi4WETuXpb08/OThx56SHx9fcViscjTTz8t58+fdxvn+vXr8u1vf1tMJpMMHTpUfvKTn8jq1asFgAwbNsx1CfPf//63REVFSUBAgEycOFGuXLnS4feSn58vCQkJEh4eLgAEgISFhYnNZpO8vLwOL6dFZy/zFhQUyKhRo8RgMLjG3rRpk1etzz/+8Y8SExPjWj/tTe+9955rrLS0NBkwYICEhITInDlz5M033xQAEhMT43bpWUTkW9/6lvzyl79sc/3U19dLWlqaREZGiq+vr4SGhkpSUpKcOnVKNm/eLAEBAQJAIiIi5M9//nOH17tI+5d5PfI5SFe88MILMmDAgB4bryfd7+cgXdHb1+eMGTPkwoULPT5uewHxikOslst95Bm9aX1+9ZDt5MmTMJlMGDp0qI4VufOKgHSXwsJCt0uC7U3Jycl6l/rASktLw9mzZ1FcXIzFixfjlVde0bskN7oGZM2aNdi5cyeqq6sxdOhQjz+XJDY2ttUlwbamXbt2eXRcvXT3+uwOZrMZsbGx+O53v4sNGzZg5MiRepfkRvvf8ZdLdnY25s2b16d+46EXPh+k99A0DQ6HA3PnznVr79OHWERdxYAQKTAgRAoMCJECA0KkwIAQKTAgRAoMCJECA0KkwIAQKTAgRAoMCJECA0Kk0O5NG1q+iUr3r6CgAADXZW/WKiARERGw2+161NLnfPUuIh1x9OhRAHdv9EY9y263IyIiolV7q9+DkH5afouQnZ2tcyXUgucgRAoMCJECA0KkwIAQKTAgRAoMCJECA0KkwIAQKTAgRAoMCJECA0KkwIAQKTAgRAoMCJECA0KkwIAQKTAgRAoMCJECA0KkwIAQKTAgRAoMCJECA0KkwIAQKTAgRAoMCJECA0KkwIAQKTAgRAoMCJECA0KkwIAQKTAgRAp8wpRO3n33Xfz+979HU1OTq62yshIAEBoa6mrz8fHBihUrkJqa2tMlEhgQ3RQVFSE2NrZDfc+cOdPhvuRZPMTSyYgRIzBmzBhomtZuH03TMGbMGIZDRwyIjhYuXAgfH592X/f19cWiRYt6sCL6Oh5i6ai8vBxWqxXtbQJN01BaWgqr1drDlVEL7kF0NGTIENhsNhgMrTeDwWCAzWZjOHTGgOhswYIFbZ6HaJqGhQsX6lARfRUPsXR248YNDB48GHfu3HFr9/HxwdWrVzFw4ECdKiOAexDdDRgwANOmTYOvr6+rzcfHB9OmTWM4vAAD4gXmz5+P5uZm179FBAsWLNCxImrBQywvUFtbi2984xu4ffs2AMBoNOLatWvo16+fzpUR9yBeIDAwELNmzYKfnx98fX3x9NNPMxxeggHxEikpKbhz5w6amprw3HPP6V0O/Y/vvbvcW35+Pi5duuSJRT2wmpqaYDKZICK4desWsrOz9S6pV4uIiMCECRO6viDxALvdLgA4cfKayW63e+JPWzx2iGW32yEinLowHT58GH//+987NQ8AOBwO3Wv3pslut3vqz9ozh1jkGVOmTNG7BPoaBsSLtPWdLNIXtwiRAgNCpMCAECkwIEQKDAiRAgNCpMCAECkwIEQKDAiRAgNCpMCAECkwIEQKXhOQJUuWICgoCJqm4fjx43qX0yXNzc3IyMiAzWZrt8+nn36KhIQEmM1mhIeHIy0tDfX19d1aV25uLqKjo6Fpmtvk7++PQYMGITExEenp6aiqqurWOnoTrwnI9u3b8fbbb+tdRpedPXsWkydPxsqVK+F0Otvsc+rUKTz55JOYOnUqKisr8d577+Gdd97BsmXLurW2pKQkXLhwATExMQgODoaIoLm5GRUVFcjOzsbQoUORlpaGUaNG4ejRo91aS2/hNQHpC06cOIGXXnoJy5Ytw6OPPtpuv1deeQVhYWH49a9/jcDAQEyYMAFpaWl49913UVhY2IMV372DY0hICBITE7Fz505kZ2fj6tWrmDlzJqqrq3u0Fm/kVQFRPQqgN4iLi0Nubi5SUlJgNBrb7HPnzh28//77mDJlitv7nT59OkQEe/fu7aly22S325GamoqKigq89dZbutbiDXQLiIggPT0dI0aMgNFoRHBwMFavXt2qX1NTE9avX4/IyEgEBARg7NixcDgcAIDMzEwEBgbCbDZj7969mD59OiwWC6xWK7KystyWk5eXh3HjxsFsNsNisWDMmDGoqam55xieduHCBdy6dQuRkZFu7TExMQCAkydPdsu4ndHyNKuDBw+62vradugw8QC73d7pH8mvXbtWNE2T119/XaqqqsTpdMrWrVsFgBw7dszVb9WqVWI0GiUnJ0eqqqpkzZo1YjAY5MiRI67lAJBDhw5JdXW1VFRUyKRJkyQwMFAaGhpEROTWrVtisVhk8+bNUldXJ1euXJHZs2dLZWVlh8a4H+PHj5e4uLhW7Xl5eQJA0tPTW70WEBAgU6dO7dQ4AMThcHRqnpiYGAkODm739ZqaGgEgERERrrbetB3u5++xPboExOl0itlslmnTprm1Z2VluQWkrq5OzGazJCcnu81rNBpl+fLlIvL/DVNXV+fq0xK0c+fOiYjIF198IQDkwIEDrWrpyBj3o72AfPTRRwJA3njjjVavWSwWsdlsnRqnOwIiIqJpmoSEhIhI79sOngyILodY586dg9PpxNSpU5X9ioqK4HQ6MXr0aFdbQEAAwsLClCez/v7+AIDGxkYAQHR0NAYNGoT58+djw4YNuHjxYpfHuF8mkwkAWt3NHQAaGhoQEBDg8TE7q7a2FiICi8UCoG9uh47SJSBlZWUA3J/m2pba2loAwLp169yu25eUlLR7CbUtAQEBOHz4MCZOnIhNmzYhOjoaycnJqKur89gYHRUWFgYAruPuFk6nE7dv30Z4eLjHx+ys4uJiAHA9G7EvboeO0iUgLf+L3uuDsZYAZWRktLr3UX5+fqfGHDVqFPbv34/y8nKkpaXB4XDgtdde8+gYHTF06FAEBQWhpKTErf3cuXMAgLFjx3p8zM764IMPANy9sgb0ze3QUboEZPTo0TAYDMjLy1P2i4iIgMlk6vIn6+Xl5Th9+jSAuxv71VdfxWOPPYbTp097bIyO8vX1xYwZM/DJJ5+4PfLg4MGD0DQNs2bN6pE62nPlyhVkZGTAarXi+eefB9A3t0NH6RKQ0NBQJCUlIScnBzt27EBNTQ1OnjyJbdu2ufUzmUxYvHgxsrKykJmZiZqaGjQ1NaGsrAyXL1/u8Hjl5eVYunQpCgsL0dDQgGPHjqGkpATx8fEeG6MzfvWrX+Hq1at4+eWXUVtbi/z8fKSnpyM1NRUjRozoljG/TuTuPYCbm5shIqisrITD4UBCQgJ8fHywZ88e1zlIX90OHeKJM/37uWpw8+ZNWbJkiQwcOFD69esnEydOlPXr1wsAsVqtcuLECRERqa+vl7S0NImMjBRfX18JDQ2VpKQkOXXqlGzdulXMZrMAkOHDh8v58+dl27ZtYrFYBIBERUVJcXGxXLx4UWw2m/Tv3198fHxkyJAhsnbtWrlz5849x+iM/Px8SUhIkPDwcNc9YsPCwsRms0leXp5b37y8PBk3bpwYjUYJDw+X1atXy+3btzs1nkjnrmLt27dPxo4dK2azWfz9/cVgMAgA1xWrcePGycaNG+X69eut5u1N28GTV7E88gCdOXPmAAB2797d1UVRJ2maBofDgblz5+pditfw5N+jV33VhMjbMCAKhYWFrb4a3taUnJysd6nUTXjzaoXY2Fh44AiUejHuQYgUGBAiBQaESIEBIVJgQIgUGBAiBQaESIEBIVJgQIgUGBAiBQaESIEBIVJgQIgUGBAiBY993b2srAzZ2dmeWhx1gp53/fBGZWVlsFqtnlmYJ363a7fbXb/B5sTJGyav+k06eUbL78q5J/YePAchUmBAiBQYECIFBoRIgQEhUmBAiBQYECIFBoRIgQEhUmBAiBQYECIFBoRIgQEhUmBAiBQYECIFBoRIgQEhUmBAiBQYECIFBoRIgQEhUmBAiBQYECIFBoRIgQEhUmBAiBQYECIFBoRIgQEhUmBAiBQYECIFBoRIgQEhUvDYMwqpc/Ly8lBQUODWVlhYCADYvHmzW3t8fDymTJnSY7XR//ERbDr561//iieffBJ+fn4wGNrekTc3N6OxsREfffQRpk2b1sMVEsCA6KapqQmDBw/G9evXlf369++PiooK+PpyZ68HnoPoxMfHBykpKfD392+3j7+/PxYsWMBw6IgB0dGzzz6LhoaGdl9vaGjAs88+24MV0dfxEEtnUVFRKC0tbfM1q9WK0tJSaJrWw1VRC+5BdDZ//nz4+fm1avf398eiRYsYDp1xD6KzM2fOYOTIkW2+9vnnn2P06NE9XBF9FQPiBUaOHIkzZ864tcXGxrZqo57HQywvsHDhQrfDLD8/PyxatEjHiqgF9yBeoLS0FA8//DBaNoWmabhw4QIefvhhfQsj7kG8QWRkJB5//HEYDAZomoYnnniC4fASDIiXWLhwIQwGA3x8fLBgwQK9y6H/4SGWl6isrER4eDgA4Msvv8TgwYN1rogAAOIBdrtdAHDi5DWT3W73xJ+2eOxLPvHx8fj5z3/uqcU9kPLy8qBpGiZPntzheebNm4cVK1ZgwoQJ3VhZ75KRkeGxZXksIFarFXPnzvXU4h5ITz31FADAYrF0eJ558+ZhwoQJXPdfsXv3bo8ti18T9SKdCQb1DF7FIlJgQIgUGBAiBQaESIEBIVJgQIgUGBAiBQaESIEBIVJgQIgUGBAiBQaESIEBIVLwmoAsWbIEQUFB0DQNx48f17ucLmlubkZGRgZsNluX+nhabm4uoqOjoWma2+Tv749BgwYhMTER6enpqKqq6rGavJ3XBGT79u14++239S6jy86ePYvJkydj5cqVcDqd992nOyQlJeHChQuIiYlBcHAwRATNzc2oqKhAdnY2hg4dirS0NIwaNQpHjx7tsbq8GX8P4kEnTpzAxo0bsWzZMtTW1rpu49PZPj1J0zSEhIQgMTERiYmJmDlzJubNm4eZM2eiuLgYwcHButanN6/ZgwDo9fehjYuLQ25uLlJSUmA0Gu+7j57sdjtSU1NRUVGBt956S+9ydKdbQEQE6enpGDFiBIxGI4KDg7F69epW/ZqamrB+/XpERkYiICAAY8eOhcPhAABkZmYiMDAQZrMZe/fuxfTp02GxWGC1WpGVleW2nLy8PIwbNw5msxkWiwVjxoxBTU3NPcd4EKWmpgIADh486Gp7YLeDJ+78YLfbO30XibVr14qmafL6669LVVWVOJ1O2bp1qwCQY8eOufqtWrVKjEaj5OTkSFVVlaxZs0YMBoMcOXLEtRwAcujQIamurpaKigqZNGmSBAYGSkNDg4iI3Lp1SywWi2zevFnq6urkypUrMnv2bKmsrOzQGPdj/PjxEhcX1+U+9wJAHA5Hp+aJiYmR4ODgdl+vqakRABIREeFq603b4X7+HtujS0CcTqeYzWaZNm2aW3tWVpZbQOrq6sRsNktycrLbvEajUZYvXy4i/98wdXV1rj4tQTt37pyIiHzxxRcCQA4cONCqlo6McT96c0BERDRNk5CQEBHpfdvBkwHR5RDr3LlzcDqdmDp1qrJfUVERnE6n2yMAAgICEBYW5noibFtaHmvW2NgIAIiOjsagQYMwf/58bNiwARcvXuzyGH1Zy8WDlptIPMjbQZeAlJWVAQBCQ0OV/WprawEA69atc7tuX1JS0qnLowEBATh8+DAmTpyITZs2ITo6GsnJyairq/PYGH1JcXExgLuPYAAe7O2gS0BMJhMAoL6+XtmvJUAZGRmQu4eDrik/P79TY44aNQr79+9HeXk50tLS4HA48Nprr3l0jL7igw8+AABMnz4dwIO9HXQJyOjRo2EwGJCXl6fsFxERAZPJ1OVP1svLy3H69GkAdzf2q6++isceewynT5/22Bh9xZUrV5CRkQGr1Yrnn38ewIO9HXQJSGhoKJKSkpCTk4MdO3agpqYGJ0+exLZt29z6mUwmLF68GFlZWcjMzERNTQ2amppQVlaGy5cvd3i88vJyLF26FIWFhWhoaMCxY8dQUlKC+Ph4j43R24gIbt26hebmZogIKisr4XA4kJCQAB8fH+zZs8d1DvJAbwdPnOnfz1WDmzdvypIlS2TgwIHSr18/mThxoqxfv14AiNVqlRMnToiISH19vaSlpUlkZKT4+vpKaGioJCUlyalTp2Tr1q1iNpsFgAwfPlzOnz8v27ZtE4vFIgAkKipKiouL5eLFi2Kz2aR///7i4+MjQ4YMkbVr18qdO3fuOUZn5OfnS0JCgoSHh7tuohwWFiY2m03y8vI63Kcz0ImrWPv27ZOxY8eK2WwWf39/MRgMAsB1xWrcuHGyceNGuX79eqt5e9N28ORVLI88/mDOnDkAPHtPVOoYTdPgcDh4b96v8OTfo1d91YTI2zAgCoWFha2+Gt7WlJycrHep1E34bV6F2NhY3b9tS/riHoRIgQEhUmBAiBQYECIFBoRIgQEhUmBAiBQYECIFBoRIgQEhUmBAiBQYECIFBoRIgQEhUvHEzxLtdrvr56OcOHnD5FU/uc3Pz8elS5e6uhgij4mIiMCECRO6vByPBISor+I5CJECA0KkwIAQKfgC4M2siNrxX7I45s+ewLAMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKsyEVC3ZRYO",
        "outputId": "dd149b0d-fc67-4384-ea2a-2b1290d3c433"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f4a505b8450>,\n",
              " <keras.layers.core.dense.Dense at 0x7f4a505b81d0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f4a505b8410>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfELBMfOCD4A",
        "outputId": "f8c62e05-f386-4dd0-f648-59c1b81e672a"
      },
      "source": [
        "model_2.predict(X_test).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh5-fozOCiNE"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Generad nuevos modelos que tengan como salida las capas intermedias de vuestro modelo funcional anterior. Realizad análisis dimensional sobre las salidas de las capas anteriores y comprobad si son las dimensiones correctas de esa capa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuchreSTChhb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "8cb71a21-30eb-49ea-86a7-77b8a8102536"
      },
      "source": [
        "dt2 = sns.load_dataset(\"penguins\")\n",
        "dt2.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>190.0</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>38.9</td>\n",
              "      <td>17.8</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3625.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.2</td>\n",
              "      <td>19.6</td>\n",
              "      <td>195.0</td>\n",
              "      <td>4675.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>34.1</td>\n",
              "      <td>18.1</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3475.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>42.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>190.0</td>\n",
              "      <td>4250.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  species     island  bill_length_mm  ...  flipper_length_mm  body_mass_g     sex\n",
              "0  Adelie  Torgersen            39.1  ...              181.0       3750.0    Male\n",
              "1  Adelie  Torgersen            39.5  ...              186.0       3800.0  Female\n",
              "2  Adelie  Torgersen            40.3  ...              195.0       3250.0  Female\n",
              "3  Adelie  Torgersen             NaN  ...                NaN          NaN     NaN\n",
              "4  Adelie  Torgersen            36.7  ...              193.0       3450.0  Female\n",
              "5  Adelie  Torgersen            39.3  ...              190.0       3650.0    Male\n",
              "6  Adelie  Torgersen            38.9  ...              181.0       3625.0  Female\n",
              "7  Adelie  Torgersen            39.2  ...              195.0       4675.0    Male\n",
              "8  Adelie  Torgersen            34.1  ...              193.0       3475.0     NaN\n",
              "9  Adelie  Torgersen            42.0  ...              190.0       4250.0     NaN\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1OSaLDsCf6y"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(10,))\n",
        "\n",
        "layer_1 = keras.layers.Dense(5, activation=\"relu\")(input_layer)\n",
        "layer_2 = keras.layers.Dense(5, activation=\"relu\")(layer_1)\n",
        "layer_3 = keras.layers.Dense(5, activation=\"relu\")(layer_2)\n",
        "\n",
        "output = keras.layers.Dense(2, activation=\"softmax\")(layer_1)\n",
        "\n",
        "#output = output_def(layer_1)\n",
        "\n",
        "model = keras.Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziEghQ2icgRj"
      },
      "source": [
        "dt2.dropna(inplace=True)\n",
        "\n",
        "X = pd.get_dummies(dt2.iloc[:,:-1])\n",
        "Y = pd.get_dummies(dt2.iloc[:,-1:])\n",
        "#aqui pongo Y con dos clases, como tengo 2 dimensiones a la salida debo utilizar la funcion softmax\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z7qORGkci8S",
        "outputId": "0a712473-e5c5-4669-b274-95a21c657996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train,Y_train, epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1060.3403\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 990.5872\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 918.9818\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 852.3703\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 788.7900\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 719.6876\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 656.3309\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 591.9772\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 530.8488\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 470.0704\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 406.5378\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 344.4115\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 287.1907\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 225.6830\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 163.7475\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 104.1126\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 44.9949\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.6087\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.9201\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 8.1856\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.9244\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.5225\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.5166\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.6132\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6499\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.4832\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.2300\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.3954\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.2202\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1849\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1416\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1625\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.3085\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1476\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0667\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0903\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0791\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0202\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0837\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1949\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1204\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.2108\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.8925\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.9725\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8515\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0006\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8599\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8130\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7663\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8074\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7433\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 3.7998\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.6634\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7479\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8403\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8113\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5709\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5854\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5739\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7153\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8123\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.6485\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5204\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5719\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.3731\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7336\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.6880\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4815\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.3516\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.4504\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4059\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5090\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4773\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5016\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.3269\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.2944\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.1550\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0850\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.2253\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0595\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0593\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.2832\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.2271\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.9596\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.9228\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9318\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8590\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8517\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8435\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8576\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0309\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8574\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0941\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7606\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0208\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8632\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5888\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7673\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9830\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7260\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.6859\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5631\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5140\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4871\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5963\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5881\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.6435\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5826\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2919\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4611\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2131\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1949\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2299\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2591\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2979\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1779\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0881\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0751\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0260\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0692\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0110\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0629\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9684\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0328\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4162\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0142\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2417\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5227\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7991\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0288\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4108\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.3785\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7433\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7802\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6823\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7346\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8157\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0970\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7468\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5467\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6711\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6718\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7334\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8907\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.3974\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9746\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8025\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8248\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7271\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4475\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5314\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4313\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0945\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3025\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2840\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3806\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3728\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3500\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3483\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2841\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2457\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5272\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3188\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1661\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1655\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1184\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1160\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0735\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9976\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9709\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0064\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0341\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9510\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9644\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9233\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8734\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8377\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0364\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2291\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8988\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9235\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0548\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8318\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8600\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0315\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0058\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7493\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7557\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8761\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6988\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8532\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8375\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6641\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6548\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6884\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6600\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6689\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6988\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7641\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a51f14390>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvwIkm4IcpKY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}