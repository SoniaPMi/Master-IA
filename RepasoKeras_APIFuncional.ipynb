{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RepasoKeras_APIFuncional.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoniaPMi/Master-IA/blob/main/RepasoKeras_APIFuncional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ1tIWQ3soHE"
      },
      "source": [
        "# Keras\n",
        "\n",
        "Keras es una librería construída para el prototipado rápido de modelos de deep learning. Las ventajas de Keras frente a otros frameworks de deep learning son obvios:\n",
        "\n",
        "- Rápido prototipado (entrenamiento y evaluación) de modelos de deep learning.\n",
        "\n",
        "- Posee una api sencilla con la que se pueden añadir estructuras complejas en redes de neuronas (capas).\n",
        "\n",
        "- Se integra con las herramientas de tensorflow de forma nativa.\n",
        "\n",
        "Keras permite construir modelos utilizando diferentes tipos de api (Application Porgram Interface). Las distintas apis tienen sus ventajas e inconvenientes, en esta clase vamos a estudiar la api secuencial y la api funcional de Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE6_0KlCzQBg"
      },
      "source": [
        "# Keras Sequential API\n",
        "\n",
        "La api secuencial de Keras permite construir modelos añadiendo capas en forma de secuencia. Su uso es muy directo siguiendo los siguientes pasos:\n",
        "\n",
        "- Definimos el modelo utilizando la clase Sequential.\n",
        "\n",
        "- Añadimos capas al modelo utilizando el método .add()\n",
        "\n",
        "- Comppilamos el modelo utilizando el método .compile()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqkkRezH2Y-Y"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrkI4arDzPVX"
      },
      "source": [
        "# Ejemplo\n",
        "dataset = sns.load_dataset(\"iris\")\n",
        "#definimos modelo\n",
        "model = keras.models.Sequential()\n",
        "#definimos capas\n",
        "layer_1 = keras.layers.Dense(10, activation=\"relu\") #10 o otro num.\n",
        "output = keras.layers.Dense(3, activation=\"softmax\") #3 clases\n",
        "#añadimos modelo\n",
        "model.add(layer_1)\n",
        "model.add(output)\n",
        "#compilamos modelo\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sPqmTkl3Ld8"
      },
      "source": [
        "X = dataset.iloc[:,:-1]\n",
        "Y = dataset.iloc[:,-1:]\n",
        "Y_dummies = pd.get_dummies(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y_dummies)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBH3c6I65X8_",
        "outputId": "b0625a62-91f7-4322-9cca-10db209048e7"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=300)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 3ms/step - loss: 2.3461\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2262\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.1121\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.9996\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.8997\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.8025\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.7130\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6296\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5589\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4950\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4356\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3822\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3360\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2935\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2527\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2178\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1822\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1535\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1248\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0970\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0743\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0557\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0362\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0218\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0082\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9931\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9833\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9725\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9617\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9523\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9438\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9350\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9272\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9185\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9116\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9025\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8954\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8879\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8802\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8729\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8653\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8587\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.8512\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8435\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8363\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8293\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8221\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8151\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8096\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8021\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7955\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7892\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7825\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7759\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7699\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7637\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7581\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7525\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7464\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7401\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7342\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7284\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7224\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7166\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7106\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7049\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6998\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6932\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6878\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6821\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6764\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6709\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6658\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6602\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6551\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6502\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6451\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6403\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6353\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6302\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6262\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6207\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6162\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6117\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6071\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6027\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5984\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5940\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5898\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5858\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5816\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5772\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5733\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5691\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5657\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5613\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5576\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5537\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5500\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5463\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5425\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5391\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5354\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5317\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5282\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5250\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5213\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5180\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5147\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5114\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5081\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5048\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5016\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4985\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4954\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4922\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4895\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4863\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4834\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4804\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4776\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4748\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4720\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4692\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4664\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4639\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4612\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4587\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4563\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4534\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4510\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4486\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4461\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4437\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4414\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4390\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4367\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4343\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4322\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4296\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4278\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4251\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4229\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4208\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4186\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4166\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4144\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4123\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4102\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4084\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4064\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4042\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4022\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4003\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3983\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3964\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3946\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3926\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3908\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3889\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3870\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3855\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3838\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3817\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3800\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3783\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3765\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3749\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3734\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3716\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3699\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3684\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3666\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3651\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3634\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3621\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3602\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3587\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3571\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3556\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3543\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3527\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3511\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3497\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3482\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3468\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3453\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3437\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3423\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3410\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3396\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3381\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3368\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3354\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3338\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3325\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3314\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3300\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3288\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3273\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3259\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3247\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3233\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3221\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3210\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3197\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3189\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3175\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3159\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3146\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3136\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3122\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3111\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3097\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3086\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3072\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3062\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3051\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3040\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3028\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3016\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3004\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2993\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2984\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2970\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2961\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2951\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2941\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2929\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2914\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2904\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2896\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2888\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2872\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2862\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2856\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2842\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2828\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2819\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2810\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2798\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2790\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2778\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2768\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2758\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2753\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2737\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2726\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2717\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2712\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2703\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2696\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2687\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2672\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2660\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2653\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2641\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2631\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2622\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2615\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2604\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2597\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2586\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2576\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2568\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2560\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2549\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2541\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2531\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2523\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2521\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2508\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2501\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2493\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2480\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2471\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2464\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2452\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2444\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2436\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2431\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2419\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2412\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2403\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2395\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2386\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2378\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2371\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2363\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2354\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2354\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2336\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2341\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2326\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2315\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2305\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2298\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2292\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2283\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2275\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a544e4350>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65HyLVmZ53Mg",
        "outputId": "a73a52af-1a70-4ff3-f033-50d9e7e94557"
      },
      "source": [
        "# Realizar predicción\n",
        "model.predict(X_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.0353526e-03, 4.9319449e-01, 5.0377017e-01],\n",
              "       [9.6630925e-01, 3.3360798e-02, 3.2996800e-04],\n",
              "       [3.6704235e-03, 2.2835828e-01, 7.6797128e-01],\n",
              "       [1.5099961e-03, 2.0131424e-01, 7.9717577e-01],\n",
              "       [5.1280959e-03, 2.9775012e-01, 6.9712180e-01],\n",
              "       [9.5498073e-01, 4.4282209e-02, 7.3697499e-04],\n",
              "       [2.0415897e-02, 7.2674638e-01, 2.5283781e-01],\n",
              "       [1.4800873e-03, 1.5061863e-01, 8.4790128e-01],\n",
              "       [8.5952617e-03, 4.6006933e-01, 5.3133535e-01],\n",
              "       [1.8264536e-03, 1.3002703e-01, 8.6814648e-01],\n",
              "       [1.4237370e-03, 2.1912579e-01, 7.7945048e-01],\n",
              "       [8.2910974e-03, 2.8690818e-01, 7.0480072e-01],\n",
              "       [1.7189730e-02, 7.5024861e-01, 2.3256169e-01],\n",
              "       [9.7329390e-01, 2.6452707e-02, 2.5335886e-04],\n",
              "       [9.5079386e-01, 4.8638716e-02, 5.6740985e-04],\n",
              "       [3.4945726e-02, 8.1886816e-01, 1.4618613e-01],\n",
              "       [9.1810209e-01, 8.1010155e-02, 8.8770880e-04],\n",
              "       [4.3601156e-03, 3.2123908e-01, 6.7440081e-01],\n",
              "       [3.3622086e-03, 2.8294960e-01, 7.1368819e-01],\n",
              "       [4.3876696e-02, 7.0044559e-01, 2.5567773e-01],\n",
              "       [9.9246866e-01, 7.4869073e-03, 4.4456858e-05],\n",
              "       [9.9206746e-01, 7.8968033e-03, 3.5670615e-05],\n",
              "       [1.7457116e-02, 6.7856622e-01, 3.0397666e-01],\n",
              "       [9.7131753e-01, 2.8430637e-02, 2.5182983e-04],\n",
              "       [3.3264169e-03, 3.9487934e-01, 6.0179430e-01],\n",
              "       [2.0499909e-02, 6.4950573e-01, 3.2999438e-01],\n",
              "       [9.5022207e-01, 4.9066164e-02, 7.1174483e-04],\n",
              "       [9.7792838e-03, 4.6458018e-01, 5.2564055e-01],\n",
              "       [2.2075433e-02, 7.8077352e-01, 1.9715106e-01],\n",
              "       [9.8236555e-01, 1.7492872e-02, 1.4153404e-04],\n",
              "       [1.5441849e-03, 2.4366018e-01, 7.5479561e-01],\n",
              "       [9.8827457e-01, 1.1676574e-02, 4.8913804e-05],\n",
              "       [1.5283336e-03, 1.7608197e-01, 8.2238966e-01],\n",
              "       [2.6778837e-03, 1.6662310e-01, 8.3069903e-01],\n",
              "       [3.4250987e-03, 2.3517428e-01, 7.6140064e-01],\n",
              "       [1.1972948e-02, 5.2710724e-01, 4.6091977e-01],\n",
              "       [9.8008019e-01, 1.9688077e-02, 2.3180504e-04],\n",
              "       [6.3124960e-03, 4.1427600e-01, 5.7941145e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iDZAFdO7oWQ"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Entrenad un modelo de 3 capas densas utilizando la api secuencial de Keras para el dataset penguins. El objetivo es clasificar el sexo del pingüino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "TwN1QZOgRFzU",
        "outputId": "c48cf6e6-ab66-459e-ef3a-57d6f23c3a40"
      },
      "source": [
        "dt2 = sns.load_dataset(\"penguins\")\n",
        "dt2.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>190.0</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>38.9</td>\n",
              "      <td>17.8</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3625.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.2</td>\n",
              "      <td>19.6</td>\n",
              "      <td>195.0</td>\n",
              "      <td>4675.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>34.1</td>\n",
              "      <td>18.1</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3475.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>42.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>190.0</td>\n",
              "      <td>4250.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  species     island  bill_length_mm  ...  flipper_length_mm  body_mass_g     sex\n",
              "0  Adelie  Torgersen            39.1  ...              181.0       3750.0    Male\n",
              "1  Adelie  Torgersen            39.5  ...              186.0       3800.0  Female\n",
              "2  Adelie  Torgersen            40.3  ...              195.0       3250.0  Female\n",
              "3  Adelie  Torgersen             NaN  ...                NaN          NaN     NaN\n",
              "4  Adelie  Torgersen            36.7  ...              193.0       3450.0  Female\n",
              "5  Adelie  Torgersen            39.3  ...              190.0       3650.0    Male\n",
              "6  Adelie  Torgersen            38.9  ...              181.0       3625.0  Female\n",
              "7  Adelie  Torgersen            39.2  ...              195.0       4675.0    Male\n",
              "8  Adelie  Torgersen            34.1  ...              193.0       3475.0     NaN\n",
              "9  Adelie  Torgersen            42.0  ...              190.0       4250.0     NaN\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNSvJgXHRV6s"
      },
      "source": [
        "#definimos modelo\n",
        "model2 = keras.models.Sequential()\n",
        "#definimos capas\n",
        "layer_1 = keras.layers.Dense(10, activation=\"relu\") #10 o otro num.\n",
        "layer_2 = keras.layers.Dense(5, activation=\"relu\") #10 o otro num.\n",
        "layer_3 = keras.layers.Dense(7, activation=\"relu\") #10 o otro num.\n",
        "output = keras.layers.Dense(2, activation=\"softmax\") #2 clases perq  tengo separado male female\n",
        "#añadimos modelo\n",
        "model2.add(layer_1)\n",
        "model2.add(layer_2)\n",
        "model2.add(layer_3)\n",
        "model2.add(output)\n",
        "#compilamos modelo\n",
        "model2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
        "#como estamos entre 0 y 1, la loss podria ser va binaria y usaria una sigmoid en la salida"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d49C0p5tR1RL"
      },
      "source": [
        "dt2.dropna(inplace=True)\n",
        "\n",
        "X = pd.get_dummies(dt2.iloc[:,:-1])\n",
        "Y = pd.get_dummies(dt2.iloc[:,-1:])\n",
        "#aqui pongo Y con dos clases, como tengo 2 dimensiones a la salida debo utilizar la funcion softmax\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
        "#"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW3ciFMASdW_",
        "outputId": "dc617add-ea20-4e17-868e-be5b3efa51fa"
      },
      "source": [
        "model2.fit(X_train, Y_train, epochs=300)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 55.2586\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 39.7583\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 26.6824\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 15.4088\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.5457\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2229\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5205\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0178\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0912\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7513\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7326\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7236\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7127\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7005\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6948\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7061\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7021\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6960\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6927\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6975\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6934\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6933\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6959\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6950\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6957\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7004\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7276\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7047\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7000\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6939\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6917\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6975\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7018\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7041\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6947\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6963\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6965\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7135\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7015\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6921\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7005\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7065\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7030\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7021\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6923\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7036\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6915\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6956\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7128\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6969\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6910\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6907\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6951\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6977\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6923\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7097\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7204\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6876\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6894\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6953\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7147\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6946\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6918\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7282\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7219\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6850\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6844\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7044\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7125\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6944\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7102\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7244\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6965\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7030\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6911\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6986\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7045\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6946\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6948\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7080\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6993\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6956\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6948\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7158\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7173\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7127\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6897\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6954\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6906\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6889\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6895\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6963\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6982\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6934\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6970\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7014\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6876\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7000\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6972\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6873\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6831\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6849\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6838\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6900\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6950\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6862\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7069\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6919\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6879\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6829\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6854\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6914\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6805\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7403\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7158\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6882\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6960\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6995\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6943\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6873\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7305\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6843\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6887\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7177\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7313\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6968\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7252\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7462\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6825\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7006\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7361\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7073\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7175\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6977\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6842\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6824\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6888\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6814\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6801\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6930\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6780\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7191\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7094\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7071\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7370\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7093\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7211\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7097\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7505\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6916\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6924\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6841\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6942\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6783\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6847\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6842\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6956\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7311\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7175\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6753\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7339\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6821\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7361\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7116\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6759\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6941\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6749\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6845\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6857\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6851\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6831\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7159\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6805\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6907\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6821\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7192\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6836\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6877\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6976\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6820\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7027\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7034\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6879\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6807\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6816\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6921\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6877\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6864\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7000\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7377\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7209\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6854\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6923\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6873\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6838\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6772\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6768\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6989\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6873\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6806\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6936\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6901\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6760\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6749\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6910\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7069\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6932\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6794\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6744\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6813\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6968\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6982\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7006\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6899\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6941\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6873\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6782\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6760\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7073\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7057\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6916\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6740\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6786\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6839\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6623\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6914\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6739\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7143\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6683\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6680\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6792\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6773\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6779\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6996\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6767\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6802\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6770\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6791\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6726\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6685\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6704\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6788\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6991\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6775\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6862\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6923\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6780\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6789\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6716\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6683\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6651\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6930\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6786\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6671\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6761\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6701\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6744\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6752\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6706\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6792\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6707\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6832\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6719\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6671\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6689\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6629\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6663\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6712\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6636\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6682\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6804\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6751\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6641\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6652\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6850\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6973\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6788\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6979\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6790\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7154\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6768\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6728\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6612\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6663\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6619\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6633\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6584\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6654\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6661\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6712\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6628\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6591\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6600\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6624\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6599\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6638\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6573\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6581\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6589\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6617\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a505bd910>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BwC015CTMP0",
        "outputId": "0308a13e-3c10-42f7-85d7-f8ade88a2ae0"
      },
      "source": [
        "# Realizar predicción\n",
        "model2.predict(X_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48829862, 0.51170135],\n",
              "       [0.50395197, 0.49604806],\n",
              "       [0.5660823 , 0.43391776],\n",
              "       [0.44926423, 0.5507357 ],\n",
              "       [0.5130433 , 0.48695666],\n",
              "       [0.5216806 , 0.47831944],\n",
              "       [0.43006882, 0.5699312 ],\n",
              "       [0.4498684 , 0.5501316 ],\n",
              "       [0.47555205, 0.524448  ],\n",
              "       [0.4525775 , 0.54742247],\n",
              "       [0.45171192, 0.54828805],\n",
              "       [0.52268565, 0.4773143 ],\n",
              "       [0.41321445, 0.58678555],\n",
              "       [0.52571887, 0.47428116],\n",
              "       [0.5257531 , 0.4742469 ],\n",
              "       [0.5153036 , 0.48469642],\n",
              "       [0.5803056 , 0.4196944 ],\n",
              "       [0.54278   , 0.45722005],\n",
              "       [0.4891489 , 0.51085114],\n",
              "       [0.5256846 , 0.47431538],\n",
              "       [0.5096271 , 0.4903729 ],\n",
              "       [0.4409958 , 0.5590042 ],\n",
              "       [0.4783423 , 0.52165776],\n",
              "       [0.458004  , 0.541996  ],\n",
              "       [0.38836062, 0.6116393 ],\n",
              "       [0.50055695, 0.49944305],\n",
              "       [0.5057905 , 0.49420956],\n",
              "       [0.5480688 , 0.45193112],\n",
              "       [0.49860767, 0.50139236],\n",
              "       [0.4033759 , 0.59662414],\n",
              "       [0.47272915, 0.5272709 ],\n",
              "       [0.53164256, 0.4683575 ],\n",
              "       [0.56883687, 0.4311631 ],\n",
              "       [0.3942374 , 0.6057626 ],\n",
              "       [0.41566584, 0.5843342 ],\n",
              "       [0.47850218, 0.52149785],\n",
              "       [0.5257797 , 0.47422025],\n",
              "       [0.5205154 , 0.47948465],\n",
              "       [0.52873874, 0.47126126],\n",
              "       [0.54878306, 0.45121694],\n",
              "       [0.40674782, 0.5932522 ],\n",
              "       [0.43261763, 0.5673824 ],\n",
              "       [0.50162506, 0.49837497],\n",
              "       [0.4462496 , 0.5537504 ],\n",
              "       [0.44163537, 0.5583646 ],\n",
              "       [0.5453538 , 0.45464617],\n",
              "       [0.42397964, 0.57602036],\n",
              "       [0.43328446, 0.5667156 ],\n",
              "       [0.5133826 , 0.48661745],\n",
              "       [0.5395595 , 0.46044055],\n",
              "       [0.42414364, 0.5758564 ],\n",
              "       [0.52266663, 0.47733337],\n",
              "       [0.4614718 , 0.5385282 ],\n",
              "       [0.45169306, 0.54830694],\n",
              "       [0.5346277 , 0.4653723 ],\n",
              "       [0.5083992 , 0.49160084],\n",
              "       [0.5501354 , 0.44986463],\n",
              "       [0.45778048, 0.54221946],\n",
              "       [0.55631673, 0.4436833 ],\n",
              "       [0.45726168, 0.5427383 ],\n",
              "       [0.5120712 , 0.48792887],\n",
              "       [0.46732035, 0.5326796 ],\n",
              "       [0.4964905 , 0.50350946],\n",
              "       [0.5036163 , 0.49638373],\n",
              "       [0.4711434 , 0.5288566 ],\n",
              "       [0.5430299 , 0.45697013],\n",
              "       [0.48073006, 0.51926994],\n",
              "       [0.5305671 , 0.46943283],\n",
              "       [0.5002594 , 0.4997406 ],\n",
              "       [0.50524503, 0.494755  ],\n",
              "       [0.52004313, 0.4799569 ],\n",
              "       [0.5466739 , 0.45332617],\n",
              "       [0.5488927 , 0.45110738],\n",
              "       [0.5091428 , 0.49085718],\n",
              "       [0.51409155, 0.48590842],\n",
              "       [0.42212123, 0.57787883],\n",
              "       [0.3862388 , 0.6137612 ],\n",
              "       [0.39454356, 0.6054565 ],\n",
              "       [0.5139696 , 0.4860304 ],\n",
              "       [0.5093411 , 0.4906589 ],\n",
              "       [0.5316083 , 0.46839163],\n",
              "       [0.5417157 , 0.4582843 ],\n",
              "       [0.52880716, 0.47119284],\n",
              "       [0.56899965, 0.4310003 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLCbHARt7xdw"
      },
      "source": [
        "# Eliminar capas de un modelo secuencial.\n",
        "\n",
        "Es posible eliminar capas de un modelo secuencial utilizando el método .pop()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAWJg4OYP73Q",
        "outputId": "81750a00-8778-483b-b78c-d4dbd7d3bbcf"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.dense.Dense at 0x7f4ad35ba650>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6jgDxFbP-4e",
        "outputId": "15b6d2dc-5122-4743-e29d-802c413a00a1"
      },
      "source": [
        "model.layers[0].weights #son los W de las diferentes capas"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense/kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
              " array([[ 0.5478236 , -0.4252265 , -0.41459036, -0.17898205,  0.18284541,\n",
              "          0.36025372,  0.13179503, -0.3643138 ,  0.36933488,  0.00672349],\n",
              "        [-0.10433403,  0.2546515 , -0.64266753, -0.64485687,  0.5540829 ,\n",
              "          0.82146364,  0.34323695,  0.0020631 ,  0.44959253,  0.27308536],\n",
              "        [ 0.80731815, -0.00590283,  0.10032845, -0.23086575, -0.7480583 ,\n",
              "         -0.52452904, -0.13693978, -0.27311718,  0.18949164, -0.72750664],\n",
              "        [ 0.38672787, -0.6218965 , -0.3837358 , -0.5141902 ,  0.09003341,\n",
              "         -0.9982998 ,  0.22708744, -0.47148582, -0.9395914 , -0.69880164]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=\n",
              " array([-0.21253285,  0.        ,  0.        ,  0.        ,  0.23966628,\n",
              "         0.44172528, -0.14751875,  0.        ,  0.28619382, -0.11556315],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNrvfx1qQFWM",
        "outputId": "2fea2dfa-6931-4452-9454-c870b8e78bce"
      },
      "source": [
        "model.layers[0].weights[0] #son los w de la primera capa (10 columnas = 10 neuronas) y 4 filas, salidas"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'dense/kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
              "array([[ 0.5478236 , -0.4252265 , -0.41459036, -0.17898205,  0.18284541,\n",
              "         0.36025372,  0.13179503, -0.3643138 ,  0.36933488,  0.00672349],\n",
              "       [-0.10433403,  0.2546515 , -0.64266753, -0.64485687,  0.5540829 ,\n",
              "         0.82146364,  0.34323695,  0.0020631 ,  0.44959253,  0.27308536],\n",
              "       [ 0.80731815, -0.00590283,  0.10032845, -0.23086575, -0.7480583 ,\n",
              "        -0.52452904, -0.13693978, -0.27311718,  0.18949164, -0.72750664],\n",
              "       [ 0.38672787, -0.6218965 , -0.3837358 , -0.5141902 ,  0.09003341,\n",
              "        -0.9982998 ,  0.22708744, -0.47148582, -0.9395914 , -0.69880164]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4a4s7_V6dRW"
      },
      "source": [
        "model2.pop() #borra la última capa"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlfnCZkVV0yC",
        "outputId": "d3d79c32-7b6e-47a8-d313-d9c38d546758"
      },
      "source": [
        "model2.layers #quito la ultima capa, en model 2 me queda con las 3 layers \n",
        "#si cada capa se dedica a algo, y me dejo la capa del controrno por ejemplo, y me quedaria en la salida el controrno"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.dense.Dense at 0x7f4a505fae50>,\n",
              " <keras.layers.core.dense.Dense at 0x7f4a5079e910>,\n",
              " <keras.layers.core.dense.Dense at 0x7f4a50613810>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLykN8GY8SZI",
        "outputId": "dec3c584-6756-4849-927a-355ba6cfef67"
      },
      "source": [
        "model.predict(X_train).shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(249, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsapglaJQ2k_",
        "outputId": "990c7552-8552-47ee-ba9b-4adc50bb3ca3"
      },
      "source": [
        "model.predict(X_train) #"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 48.1,  15.1, 209. , ...,   1. ,   0. ,   0. ],\n",
              "       [ 34.6,  17.2, 189. , ...,   0. ,   0. ,   1. ],\n",
              "       [ 48.4,  16.3, 220. , ...,   1. ,   0. ,   0. ],\n",
              "       ...,\n",
              "       [ 41.1,  17.6, 182. , ...,   0. ,   0. ,   1. ],\n",
              "       [ 48.7,  15.1, 222. , ...,   1. ,   0. ,   0. ],\n",
              "       [ 37. ,  16.5, 185. , ...,   0. ,   1. ,   0. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcllTz2Q8UH_",
        "outputId": "91de0926-dad2-42c6-df88-45322243744e"
      },
      "source": [
        "len(model.layers)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HgsPWzi9OMr"
      },
      "source": [
        "# API Funcional\n",
        "\n",
        "La api funcional de Keras plantea construir un modelo mediante funciones. Las capas definidas en esta api se estructuran como funciones de Python cuya entrada es la salida de la capa anterior. Para construir un modelo utilizando la API Funcional de Keras hay que seguir los siguientes pasos:\n",
        "\n",
        "- Definir la entrada con keras.layers.Input()\n",
        "- Definir las capas de keras.layers\n",
        "- Definir el modelo con keras.models.Model()\n",
        "- Compilar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZgVO8rk_5Rg"
      },
      "source": [
        "dataset = sns.load_dataset(\"iris\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myGihdhu9NhT"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(4,))\n",
        "\n",
        "layer_1 = keras.layers.Dense(5, activation=\"relu\")(input_layer)\n",
        "\n",
        "output = keras.layers.Dense(3, activation=\"softmax\")(layer_1)\n",
        "\n",
        "#output = output_def(layer_1)\n",
        "\n",
        "model = keras.Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyqA_4wR8ZD3"
      },
      "source": [
        "X = dataset.iloc[:,:-1]\n",
        "Y = dataset.iloc[:,-1:]\n",
        "Y_dummies = pd.get_dummies(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y_dummies)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUi4MMH2_9hI",
        "outputId": "d7f8c383-0003-433c-b5b5-bf1488f233d9"
      },
      "source": [
        "model.fit(X_train,Y_train, epochs=200)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2232\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.1738\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.1270\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.0780\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.0322\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.9847\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.9412\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.8948\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.8511\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.8083\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.7663\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.7259\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6869\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6497\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6097\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.5755\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5403\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5050\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4727\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4403\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4076\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3772\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3470\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3191\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2901\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2642\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2384\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2134\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1902\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1671\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1453\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1224\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1010\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0813\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0617\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.0435\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0247\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0087\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9896\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9741\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9596\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9438\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9296\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9162\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.9028\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8907\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8781\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8672\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8550\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8439\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8336\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.8233\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8130\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8033\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7940\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7847\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7751\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7661\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7570\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7483\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7394\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7318\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7227\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7152\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7076\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6999\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6922\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6857\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6782\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6716\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6652\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6582\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6522\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6461\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6398\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6340\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6285\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6228\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6174\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6116\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6063\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6013\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5958\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5911\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5861\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5817\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5771\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5724\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5679\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5635\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5593\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5551\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5509\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5469\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5427\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5389\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5350\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5310\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5273\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5234\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5198\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5161\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5125\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5091\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5058\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5022\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4989\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4957\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4923\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4892\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4859\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4828\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4799\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4767\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4739\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4710\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4681\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4652\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4625\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4598\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4571\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4543\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4516\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4490\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4464\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4438\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4414\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4387\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4362\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4336\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4312\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4291\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4266\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4241\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4217\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4197\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4170\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4147\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4124\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4101\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4079\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4058\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4034\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4012\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3990\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3968\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3947\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3925\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3903\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3882\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3861\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3841\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3821\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3802\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3780\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3759\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3739\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3720\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3699\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3679\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3662\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3641\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3622\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3602\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3584\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3566\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3548\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3529\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3509\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3491\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3471\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3453\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3436\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3418\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3400\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3381\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3364\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3347\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3330\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3312\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3294\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3276\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3260\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3243\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3227\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3211\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3195\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3177\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3162\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3146\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3129\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3115\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3099\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3083\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3067\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3052\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3036\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3021\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3007\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a5439d0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8CFBzwKBEYH"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Construid un modelo de 3 capas densas utilizando la API Funcional de Keras sobre el dataset penguins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a12hrOu0BkH3"
      },
      "source": [
        "# Acceder a las capas intermedias de un modelo\n",
        "\n",
        "A veces es interesante poder acceder a la salida de una capa intermedia de un modelo entrenado previamente. Para ello es necesario construir un nuevo modelo definiendo una nueva salida.\n",
        "\n",
        "Una vez definida la nueva salida es posible aplicar análisis dimensional (comprobar las dimensiones de la salida) para comprender más acerca del modelo y si hemos elegido la capa correcta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMvVKvM4__S5"
      },
      "source": [
        "new_output = model.layers[1]\n",
        "model_2 = keras.Model(inputs=input_layer, outputs=new_output.output)\n",
        "model_2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "3Fz7CLDmZpHr",
        "outputId": "7d4d8f3f-aeaf-4054-fd5c-63e04240019a"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKsyEVC3ZRYO",
        "outputId": "dd149b0d-fc67-4384-ea2a-2b1290d3c433"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f4a505b8450>,\n",
              " <keras.layers.core.dense.Dense at 0x7f4a505b81d0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f4a505b8410>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfELBMfOCD4A",
        "outputId": "f8c62e05-f386-4dd0-f648-59c1b81e672a"
      },
      "source": [
        "model_2.predict(X_test).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh5-fozOCiNE"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Generad nuevos modelos que tengan como salida las capas intermedias de vuestro modelo funcional anterior. Realizad análisis dimensional sobre las salidas de las capas anteriores y comprobad si son las dimensiones correctas de esa capa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuchreSTChhb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "8cb71a21-30eb-49ea-86a7-77b8a8102536"
      },
      "source": [
        "dt2 = sns.load_dataset(\"penguins\")\n",
        "dt2.head(10)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>190.0</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>38.9</td>\n",
              "      <td>17.8</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3625.0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.2</td>\n",
              "      <td>19.6</td>\n",
              "      <td>195.0</td>\n",
              "      <td>4675.0</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>34.1</td>\n",
              "      <td>18.1</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3475.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>42.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>190.0</td>\n",
              "      <td>4250.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  species     island  bill_length_mm  ...  flipper_length_mm  body_mass_g     sex\n",
              "0  Adelie  Torgersen            39.1  ...              181.0       3750.0    Male\n",
              "1  Adelie  Torgersen            39.5  ...              186.0       3800.0  Female\n",
              "2  Adelie  Torgersen            40.3  ...              195.0       3250.0  Female\n",
              "3  Adelie  Torgersen             NaN  ...                NaN          NaN     NaN\n",
              "4  Adelie  Torgersen            36.7  ...              193.0       3450.0  Female\n",
              "5  Adelie  Torgersen            39.3  ...              190.0       3650.0    Male\n",
              "6  Adelie  Torgersen            38.9  ...              181.0       3625.0  Female\n",
              "7  Adelie  Torgersen            39.2  ...              195.0       4675.0    Male\n",
              "8  Adelie  Torgersen            34.1  ...              193.0       3475.0     NaN\n",
              "9  Adelie  Torgersen            42.0  ...              190.0       4250.0     NaN\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1OSaLDsCf6y"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(10,))\n",
        "\n",
        "layer_1 = keras.layers.Dense(5, activation=\"relu\")(input_layer)\n",
        "layer_2 = keras.layers.Dense(5, activation=\"relu\")(layer_1)\n",
        "layer_3 = keras.layers.Dense(5, activation=\"relu\")(layer_2)\n",
        "\n",
        "output = keras.layers.Dense(2, activation=\"softmax\")(layer_1)\n",
        "\n",
        "#output = output_def(layer_1)\n",
        "\n",
        "model = keras.Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziEghQ2icgRj"
      },
      "source": [
        "dt2.dropna(inplace=True)\n",
        "\n",
        "X = pd.get_dummies(dt2.iloc[:,:-1])\n",
        "Y = pd.get_dummies(dt2.iloc[:,-1:])\n",
        "#aqui pongo Y con dos clases, como tengo 2 dimensiones a la salida debo utilizar la funcion softmax\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
        "#"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z7qORGkci8S",
        "outputId": "0a712473-e5c5-4669-b274-95a21c657996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train,Y_train, epochs=200)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1060.3403\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 990.5872\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 918.9818\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 852.3703\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 788.7900\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 719.6876\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 656.3309\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 591.9772\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 530.8488\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 470.0704\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 406.5378\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 344.4115\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 287.1907\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 225.6830\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 163.7475\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 104.1126\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 44.9949\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.6087\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.9201\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 8.1856\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.9244\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.5225\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.5166\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.6132\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6499\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.4832\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.2300\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.3954\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.2202\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1849\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1416\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1625\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.3085\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1476\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0667\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0903\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0791\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0202\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0837\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1949\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1204\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.2108\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.8925\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.9725\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8515\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.0006\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8599\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8130\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7663\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8074\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7433\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 3.7998\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.6634\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7479\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8403\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8113\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5709\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5854\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5739\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7153\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8123\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.6485\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5204\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5719\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.3731\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7336\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.6880\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4815\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.3516\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.4504\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4059\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5090\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4773\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5016\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.3269\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.2944\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.1550\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0850\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.2253\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0595\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0593\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.2832\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.2271\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.9596\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.9228\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9318\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8590\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8517\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8435\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8576\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0309\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8574\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0941\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7606\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0208\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8632\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5888\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7673\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9830\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7260\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.6859\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5631\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5140\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4871\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5963\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5881\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.6435\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5826\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2919\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4611\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2131\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1949\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2299\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2591\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2979\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1779\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0881\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0751\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0260\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0692\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0110\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0629\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9684\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0328\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4162\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0142\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2417\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5227\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7991\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0288\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4108\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.3785\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7433\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7802\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6823\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7346\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8157\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0970\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7468\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5467\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6711\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6718\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7334\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8907\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.3974\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9746\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8025\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8248\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7271\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4475\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5314\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4313\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0945\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3025\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2840\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3806\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3728\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3500\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3483\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2841\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2457\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5272\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3188\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1661\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1655\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1184\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1160\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0735\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9976\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9709\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0064\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0341\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9510\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9644\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9233\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8734\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8377\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0364\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2291\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8988\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9235\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0548\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8318\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8600\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0315\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0058\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7493\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7557\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8761\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6988\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8532\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8375\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6641\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6548\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6884\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6600\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6689\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6988\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7641\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a51f14390>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvwIkm4IcpKY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}